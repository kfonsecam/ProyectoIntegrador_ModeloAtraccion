{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wNikmEfa5b6"
   },
   "source": [
    "# Modelo de predicción de inscripciones estudiantiles mediante técnicas de Machine Learning\n",
    "\n",
    "**Maestría en Inteligencia Artificial Aplicada**\n",
    "\n",
    "**Proyecto Integrador Sep-Nov 2025**\n",
    "\n",
    "**Avance 2. Ingeniería de características**\n",
    "\n",
    "**Equipo 14**\n",
    "\n",
    "**Integrantes:**\n",
    "\n",
    "- Alejandro Roa Solis – A01129942\n",
    "- Annette Cristina Narvaez Andrade – A00571041\n",
    "- Karla Alejandra Fonseca Márquez – A01795313\n",
    "\n",
    "\n",
    "**Patrocinador Tec de Monterrey:**\n",
    "\n",
    "Dr. Juan Arturo Nolazco Flores, Director del Hub de Ciencias y Datos de la Escuela de Ingeniería del Tec de Monterrey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyDqeTBBbO7M"
   },
   "source": [
    "En esta segunda etapa del **Proyecto Integrador**, enfocada en la *Ingeniería de características*, se busca optimizar el conjunto de datos con el fin de mejorar el rendimiento y la capacidad predictiva de los modelos de **atracción de estudiantes** para la universidad.  \n",
    "\n",
    "El objetivo general del proyecto es comprender los factores que influyen en la decisión de inscripción de los prospectos y desarrollar modelos que permitan anticipar su comportamiento para fortalecer las estrategias de captación.  \n",
    "\n",
    "Con este propósito, se decidió **dividir el dataset en tres subconjuntos**:  \n",
    "1. Aspirantes de **entrada a Prepa Tec**,  \n",
    "2. Estudiantes que **ingresan a universidad siendo egresados de Prepa Tec**, y  \n",
    "3. Aspirantes que **ingresan a universidad sin haber cursado Prepa Tec**.  \n",
    "\n",
    "Esta segmentación permite abordar de forma más precisa las particularidades de cada grupo y aplicar técnicas de *ingeniería de características* específicas —como **codificación, normalización, discretización y selección de variables**— que contribuyan a la construcción de modelos más robustos, interpretables y ajustados al contexto institucional.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3XIAGZHhzoe"
   },
   "source": [
    "## Resumen general de datos combinados\n",
    "\n",
    "**Total de registros:** 40,780  \n",
    "**Total de admitidos:** 23,010  \n",
    "\n",
    "---\n",
    "\n",
    "### Distribución por nivel académico (sin solapamientos)\n",
    "\n",
    "| Nivel académico | Registros totales | Admitidos | Tasa de admisión |\n",
    "|-----------------|------------------:|-----------:|-----------------:|\n",
    "| Preparatoria | 15,356 | 10,318 | **67.2 %** |\n",
    "| Universidad (desde Prepa Tec) | 7,621 | 6,314 | **82.8 %** |\n",
    "| Universidad (No Tec) | 17,803 | 6,378 | **35.8 %** |\n",
    "| **Total** | **40,780** | **23,010** | **56.4 % (global)** |\n",
    "\n",
    "---\n",
    "\n",
    "### Observaciones\n",
    "\n",
    "- El conjunto de datos contiene **40,780 registros únicos** después de limpiar solapamientos.  \n",
    "- La **tasa global de admisión** es del **56 %**, lo cual indica que poco más de la mitad de los prospectos son aceptados.  \n",
    "- Los aspirantes provenientes de **Prepa Tec** muestran la **mayor tasa de conversión a admisión (82.8 %)**, lo que sugiere una fuerte continuidad interna.  \n",
    "- Los alumnos de **Preparatoria** mantienen una tasa sólida (67 %), mientras que los aspirantes **No Tec** presentan un nivel de admisión considerablemente menor (36 %).  \n",
    "- Esta segmentación permitirá ajustar los modelos predictivos según el origen y nivel del prospecto, mejorando la capacidad de predicción de inscripción efectiva.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ingreso a **Prepa Tec**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8DzJEopCZkN"
   },
   "source": [
    "### Resumen Fase 1: Análisis exploratorio de datos\n",
    "El conjunto de datos, compuesto por **9,546 registros y 42 variables**, fue depurado de valores nulos, columnas constantes y outliers extremos.  \n",
    "Tras la limpieza, no se identificaron patrones sistemáticos de ausencia ni inconsistencias en las variables numéricas o categóricas.\n",
    "\n",
    "En términos descriptivos, los aspirantes admitidos muestran **promedios académicos altos** (`V_PROM_IND` ≈ 91) y **puntajes PAA sólidos** (~1,090), con edades entre **14 y 18 años**.  \n",
    "La mayoría de los estudiantes **no cuentan con beca** (≈95%), lo que genera distribuciones sesgadas hacia cero en variables financieras.  \n",
    "Las distribuciones de desempeño (`ENSAYO`, `RUBRICA`, `CV`) presentan sesgos positivos, por lo que se recomienda escalar o normalizar antes del modelado.\n",
    "\n",
    "No se identifican **tendencias temporales**, ya que el periodo corresponde únicamente a una admisión (`AD24`).  \n",
    "Las correlaciones entre variables numéricas y la variable objetivo `INSCRITO` son **débiles** (|r| < 0.2), lo que sugiere un fenómeno **multifactorial**: la inscripción depende de la combinación de varios factores, más que de una sola variable.\n",
    "\n",
    "En el análisis bivariado, se observan **diferencias significativas por campus y tipo de beca**, mientras que el género y el área académica presentan variaciones menores.  \n",
    "Existe un **leve desequilibrio de clases** en la variable `INSCRITO` (~70% inscritos, 30% no inscritos), que podría abordarse mediante técnicas de balanceo o ponderación en el modelo.\n",
    "\n",
    "**En síntesis:**  \n",
    "El dataset está limpio, balanceado y listo para la fase de modelado.  \n",
    "Las variables más prometedoras para explicar la atracción e inscripción son:  \n",
    "`V_PROM_IND`, `V_PAA_IND`, `TIPO_BECA_F`, `CAMPUS_UTILIZADO` y `EDAD`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVlr_gPDdCKg"
   },
   "source": [
    "### Ingeniería de Características (Feature Engineering) — Grupo **Prepa Tec**\n",
    "**Metodología CRISP-ML — Etapa de Preparación de los Datos**\n",
    "\n",
    "En esta etapa se transforma el dataset limpio de *Prepa Tec (admitidos)* en un conjunto de variables listas para modelado, asegurando calidad, escalabilidad y coherencia entre tipos de datos.\n",
    "\n",
    "---\n",
    "\n",
    "#### Generación de nuevas características\n",
    "   - `TIENE_BECA`: indica si el alumno cuenta con algún porcentaje de beca.\n",
    "   - `PROMEDIO_ALTO`: valor binario (1 si `V_PROM_IND` > 90).\n",
    "   - `GRUPO_EDAD`: discretización de edad en rangos *[14–15], [16], [17–18]*.\n",
    "\n",
    "#### Transformaciones no lineales**\n",
    "   - Aplicación de `log1p()` en `RUBRICA` y `ENSAYO` para reducir el sesgo positivo y normalizar distribuciones.\n",
    "\n",
    "#### Codificación de variables categóricas\n",
    "   - **Ordinales:** `CLAVE_GENERO`, `AREA`, `ORIGEN_DE_LA_SOLICITUD`, `GRUPO_EDAD` codificadas mediante `OrdinalEncoder`.\n",
    "   - **One-Hot Encoding:** variables con ≤ 20 categorías (como `TIPO_BECA_F`).\n",
    "   - **Frequency Encoding:** variables de alta cardinalidad (`CAMPUS_UTILIZADO`, `SEDE`, `NOMBRE_ESCUELA`) reemplazadas por su frecuencia relativa.\n",
    "\n",
    "#### Imputación y escalamiento\n",
    "\n",
    "   - **Imputación** con la **mediana** en variables numéricas y **moda** en categóricas para manejar valores faltantes de forma robusta.\n",
    "   - **Estandarización** mediante `StandardScaler` (media 0, desviación 1), esencial para modelos sensibles a escala (regresión, PCA, SVM, etc.).\n",
    "\n",
    "#### Selección y reducción de características\n",
    "   - Aplicación de un **filtro de baja varianza (`VarianceThreshold=0.01`)**, eliminando columnas con información redundante o casi constante.\n",
    "   - Tras este proceso, el dataset quedó reducido a **19 variables informativas**, sin pérdida relevante de información.\n",
    "\n",
    "#### Análisis exploratorio con PCA (opcional)\n",
    "   - Se consideró la proyección de **10 componentes principales** como parte del análisis exploratorio; los primeros componentes explican alrededor del **60–65% de la varianza total**, confirmando una estructura compacta sin ruido excesivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1893,
     "status": "ok",
     "timestamp": 1759614292005,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "mVY1KacgL0NB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 72,
     "status": "ok",
     "timestamp": 1759614292648,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "ZSWTZO7Xa4tK"
   },
   "outputs": [],
   "source": [
    "df_prepa_tec = pd.read_csv(\"prepa_tec_limpio.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1759614323014,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "50-zMRBNsuL9"
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# 1) Generación de nuevas variables\n",
    "# =====================\n",
    "\n",
    "# Indicadores\n",
    "df_prepa_tec['TIENE_BECA'] = (df_prepa_tec['PRC_BECA_F'] > 0).astype(int)\n",
    "\n",
    "# Promedio alto\n",
    "df_prepa_tec['PROMEDIO_ALTO'] = (df_prepa_tec['V_PROM_IND'] > 90).astype(int)\n",
    "\n",
    "# Discretización de edad (GRUPO_EDAD): [14–15], [16], [17–18]\n",
    "bins = [0, 15, 16, 18, np.inf]\n",
    "labels = ['14-15', '16', '17-18', '19+']  # incluye >18 por robustez\n",
    "df_prepa_tec['GRUPO_EDAD'] = pd.cut(df_prepa_tec['EDAD'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Transformaciones no lineales (sesgo positivo)\n",
    "df_prepa_tec['RUBRICA_LOG'] = np.log1p(df_prepa_tec['RUBRICA'])\n",
    "df_prepa_tec['ENSAYO_LOG'] = np.log1p(df_prepa_tec['ENSAYO'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1759614345645,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "aKvhb2nJsxAN"
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# 2) Frequency Encoding para alta cardinalidad\n",
    "#    (CAMPUS_UTILIZADO, SEDE, NOMBRE_ESCUELA, etc.)\n",
    "# =====================\n",
    "\n",
    "high_card_cols = [c for c in ['CAMPUS_UTILIZADO', 'SEDE', 'NOMBRE_ESCUELA']\n",
    "                  if c in df_prepa_tec.columns]\n",
    "\n",
    "for col in high_card_cols:\n",
    "    freqs = df_prepa_tec[col].value_counts(normalize=True)\n",
    "    df_prepa_tec[col + '_FREQ'] = df_prepa_tec[col].map(freqs).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1759614380000,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "eTWwGTC5s7Sv"
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# 3) Definición de conjuntos de variables\n",
    "# =====================\n",
    "\n",
    "# Numéricas originales + derivadas (sin contar las que serán codificadas)\n",
    "num_features = [c for c in [\n",
    "    'V_PROM_IND', 'V_PAA_IND', 'PUNTAJE_EUC', 'EDAD',\n",
    "    'PRC_BECA_F', 'PRC_CREDITO_F',\n",
    "    'RUBRICA_LOG', 'ENSAYO_LOG',\n",
    "    'TIENE_BECA', 'PROMEDIO_ALTO'\n",
    "] if c in df_prepa_tec.columns]\n",
    "\n",
    "# Frecuencias creadas (ya son numéricas)\n",
    "freq_features = [c for c in [f + '_FREQ' for f in high_card_cols] if c in df_prepa_tec.columns]\n",
    "\n",
    "# Categóricas a codificación ordinal (según tu especificación)\n",
    "ordinal_cat = [c for c in ['CLAVE_GENERO', 'AREA', 'ORIGEN_DE_LA_SOLICITUD', 'GRUPO_EDAD']\n",
    "               if c in df_prepa_tec.columns]\n",
    "\n",
    "# Categóricas a One-Hot (≤ 20 categorías)\n",
    "onehot_cat = [c for c in ['TIPO_BECA_F', 'AREA'] if c in df_prepa_tec.columns]  # AREA puede ir en OHE si lo prefieres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1759614398824,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "MN4JcIaRs9HI"
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# 4) Preprocesadores por tipo\n",
    "# =====================\n",
    "\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "ordinal_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ord', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "onehot_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(drop='first', handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num',   num_pipeline, num_features + freq_features),\n",
    "        ('ord',   ordinal_pipeline, ordinal_cat),\n",
    "        ('ohe',   onehot_pipeline, onehot_cat),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1759614408196,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "C7sHRPFktu0Z"
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# 5) Filtro de baja varianza\n",
    "# =====================\n",
    "\n",
    "selector = VarianceThreshold(threshold=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1759614431430,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "MH2dsXjitxEn"
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# 6) Pipeline completo\n",
    "# =====================\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('pre', preprocessor),\n",
    "    ('var', selector),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1759614446744,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "cXzVPotfMWGg",
    "outputId": "b77e7999-e92c-4b26-b781-1fbf66754633"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del conjunto transformado: (9546, 19)\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# 7) Ajuste y transformación\n",
    "# =====================\n",
    "\n",
    "X_prepared = pipeline.fit_transform(df_prepa_tec)\n",
    "print(\"Dimensiones del conjunto transformado:\", X_prepared.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WT_ouD6YxSE4"
   },
   "source": [
    "### Resultados cuantitativos — Feature Engineering (Prepa Tec)\n",
    "\n",
    "| **Etapa**                          | **N° Variables** | **Acción realizada** |\n",
    "|-----------------------------------|------------------|----------------------|\n",
    "| Dataset limpio inicial            | 42               | Después de eliminar columnas constantes, nulas y outliers extremos |\n",
    "| Tras generación de nuevas vars.   | 45               | Se añadieron `TIENE_BECA`, `PROMEDIO_ALTO`, `GRUPO_EDAD` |\n",
    "| Tras transformaciones no lineales | 47               | Aplicación de `log1p()` en `RUBRICA` y `ENSAYO` para normalizar |\n",
    "| Tras codificación y escalamiento  | 90+              | Variables categóricas transformadas con *One-Hot*, *Ordinal* y *Frecuencia* |\n",
    "| Tras filtro de baja varianza      | 19               | Reducción significativa: eliminación de variables redundantes o con varianza < 0.01 |\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusiones de la fase de Feature Engineering\n",
    "\n",
    "- El dataset final es **numérico, estandarizado y balanceado**, listo para ser utilizado en algoritmos de clasificación supervisada.  \n",
    "- Se crearon **nuevas variables derivadas** (`TIENE_BECA`, `PROMEDIO_ALTO`, `GRUPO_EDAD`) que aumentan la interpretabilidad y relevancia predictiva.  \n",
    "- Las transformaciones **logarítmicas (`log1p`)** aplicadas en `RUBRICA` y `ENSAYO` corrigieron la asimetría positiva, estabilizando su distribución.  \n",
    "- Se aplicó una **codificación mixta**:\n",
    "  - *Ordinal Encoding* en variables con orden implícito (`CLAVE_GENERO`, `AREA`, `GRUPO_EDAD`).  \n",
    "  - *One-Hot Encoding* para categorías discretas (`TIPO_BECA_F`).  \n",
    "  - *Frequency Encoding* para categorías de alta cardinalidad (`CAMPUS_UTILIZADO`, `SEDE`, `NOMBRE_ESCUELA`).  \n",
    "- La **imputación robusta (mediana/moda)** y la **estandarización (Z-score)** homogenizaron escalas y redujeron la sensibilidad a outliers.  \n",
    "- El **filtro de baja varianza (0.01)** consolidó un conjunto compacto de **19 variables realmente informativas**, eliminando redundancia sin pérdida de poder predictivo.  \n",
    "\n",
    "---\n",
    "\n",
    "**Dimensiones finales:**  \n",
    "- `X` (características): **9,546 filas × 19 columnas**  \n",
    "- `y` (variable objetivo): **INSCRITO**\n",
    "\n",
    "**Variables más relevantes generadas:**  \n",
    "`V_PROM_IND`, `V_PAA_IND`, `PRC_BECA_F`, `TIPO_BECA_F`, `AREA`, `CAMPUS_UTILIZADO`, `GRUPO_EDAD`, `TIENE_BECA`, `PROMEDIO_ALTO`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Ajqg2YfHkZK"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ingreso a **Profesional desde Prepa Tec**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EM4ouu8HmEq",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Resumen Fase 1: Análisis exploratorio de datos\n",
    "\n",
    "El conjunto de datos del grupo **Profesional**, compuesto por **6,314 registros y 44 variables**, fue depurado eliminando columnas constantes, identificadores únicos y campos con alta proporción de valores nulos. Tras la limpieza, no se detectaron inconsistencias en las variables numéricas ni categóricas, y las distribuciones resultaron coherentes con el contexto académico y socioeconómico de los aspirantes.\n",
    "\n",
    "En términos descriptivos, los estudiantes muestran **promedios académicos altos (V_PROM_IND ≈ 90)** y **puntajes PAA competitivos (~1,300)**, con edades concentradas entre **16 y 22 años**. La mayoría **no cuenta con beca ni crédito educativo**, lo que genera sesgos marcados hacia cero en las variables financieras (`PRC_BECA_F`, `PRC_CREDITO_F`). No se observaron valores atípicos erróneos, únicamente casos de alto rendimiento académico o apoyo económico elevado.\n",
    "\n",
    "Las correlaciones entre las variables numéricas y la variable objetivo `INSCRITO` fueron **bajas (|r| < 0.2)**, lo que sugiere que la decisión de inscripción es un fenómeno **multifactorial**, influido por la combinación de desempeño académico, apoyos económicos y contexto institucional.\n",
    "\n",
    "En el análisis bivariado, se evidenciaron diferencias relevantes por **campus** y **tipo de beca**, mientras que el **género**, la **nacionalidad** y el **área académica** mostraron variaciones menores. La variable objetivo presenta un **leve desbalance** (~80% inscritos, 20% no inscritos), adecuado para modelado con estrategias de ponderación o muestreo estratificado.\n",
    "\n",
    "En síntesis, el dataset se encuentra **limpio, estructurado y listo para la fase de modelado predictivo**.  \n",
    "Las variables más prometedoras para explicar la **inscripción** son:  \n",
    "**V_PROM_IND**, **V_PAA_IND**, **TIPO_BECA_F**, **CAMPUS_UTILIZADO** y **EDAD**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9voi4YL9IAOI"
   },
   "source": [
    "### Ingeniería de Características (Feature Engineering) — Grupo **Profesional desde Prepa Tec**\n",
    "\n",
    "En esta fase se implementan transformaciones sobre las variables originales con el fin de mejorar la calidad y la representatividad de los datos para los modelos de aprendizaje automático.  \n",
    "El objetivo es **transformar los datos crudos en un conjunto de características útiles, informativas y escalables**, reduciendo la redundancia y optimizando el desempeño del modelo.\n",
    "\n",
    "---\n",
    "\n",
    "#### Generación de nuevas características\n",
    "\n",
    "A partir de las variables originales, se generaron indicadores derivados que aportan información adicional:\n",
    "\n",
    "- **V_PAA_MISSING**: identifica aspirantes sin puntaje PAA (`V_PAA_IND == 0` o `NaN`).\n",
    "- **TIENE_BECA**: indica si el porcentaje de beca (`PRC_BECA_F`) es mayor a 0.\n",
    "- **TIENE_CREDITO**: indica si el porcentaje de crédito (`PRC_CREDITO_F`) es mayor a 0.\n",
    "- **RANGO_EDAD**: segmenta la edad en tres categorías: *menor de 18*, *18–20*, *mayor de 20* años.\n",
    "\n",
    "Estas variables permiten representar comportamientos y condiciones que no se observan directamente en los datos numéricos originales.\n",
    "\n",
    "---\n",
    "\n",
    "#### Codificación de variables categóricas\n",
    "\n",
    "Para que los modelos numéricos (regresión logística, árboles, redes neuronales, etc.) puedan interpretar variables categóricas:\n",
    "\n",
    "- Se aplicará **codificación one-hot** a variables no ordinales con cardinalidad baja o media (`CLAVE_GENERO`, `AREA`, `TIPO_BECA_F`, `CAMPUS_UTILIZADO`, `ORIGEN_DE_LA_SOLICITUD`).\n",
    "- Variables con mayor cardinalidad (`NACIONALIDAD`) se agruparon previamente en la fase de limpieza (“Otros” para categorías con <30 registros).\n",
    "\n",
    "Esto garantiza que las relaciones no lineales entre categorías sean capturadas sin introducir sesgos ordinales artificiales.\n",
    "\n",
    "---\n",
    "\n",
    "#### Escalamiento de variables numéricas\n",
    "\n",
    "Se estandarizarán las variables numéricas continuas (`V_PROM_IND`, `V_PAA_IND`, `PUNTAJE_EUC`, `EDAD`, `PRC_BECA_F`, `PRC_CREDITO_F`) mediante:\n",
    "\n",
    "- **Estandarización (Z-score)**: para algoritmos basados en distancia (KNN, SVM, regresión logística).\n",
    "- **Normalización (Min-Max)**: en caso de emplear modelos sensibles a magnitudes absolutas (redes neuronales).\n",
    "\n",
    "---\n",
    "\n",
    "#### Selección y reducción de características\n",
    "\n",
    "Para evitar redundancia y sobreajuste:\n",
    "\n",
    "- **Umbral de varianza:** eliminación de variables con varianza ≈ 0.  \n",
    "- **Correlación de Pearson:** remoción de variables altamente correlacionadas (r > 0.85).  \n",
    "- **ANOVA y Chi-cuadrado:** para estimar relevancia respecto a la variable `INSCRITO`.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1759613551095,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "Yr6YmPJLI_1I"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1759613627744,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "pmjUH_ZiIt74",
    "outputId": "5d3cfc3c-50ce-4301-e618-fd92b715f3e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6312, 43)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pro_tec = pd.read_csv(\"profesional_tec_limpio.csv\")\n",
    "df_pro_tec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1759613629054,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "JbcK7s-pIoOy",
    "outputId": "c2f5bfa8-f5f4-4059-91c6-7304e9132cc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6312, 46)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =====================\n",
    "# 1. Generación de nuevas variables\n",
    "# =====================\n",
    "\n",
    "df_pro_tec['V_PAA_MISSING'] = df_pro_tec['V_PAA_IND'].isna().astype(int)\n",
    "df_pro_tec['TIENE_BECA'] = (df_pro_tec['PRC_BECA_F'] > 0).astype(int)\n",
    "df_pro_tec['TIENE_CREDITO'] = (df_pro_tec['PRC_CREDITO_F'] > 0).astype(int)\n",
    "\n",
    "# Rango de edad\n",
    "bins = [0, 17, 20, 30]\n",
    "labels = ['<18', '18-20', '>20']\n",
    "df_pro_tec['RANGO_EDAD'] = pd.cut(df_pro_tec['EDAD'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "df_pro_tec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1759613631803,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "RcyteU9QI6gV"
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# 2. Definición de variables\n",
    "# =====================\n",
    "\n",
    "num_features = ['V_PROM_IND', 'V_PAA_IND', 'PUNTAJE_EUC', 'EDAD', 'PRC_BECA_F', 'PRC_CREDITO_F']\n",
    "cat_features = ['CLAVE_GENERO', 'NACIONALIDAD', 'AREA', 'TIPO_BECA_F', 'CAMPUS_UTILIZADO', 'ORIGEN_DE_LA_SOLICITUD', 'RANGO_EDAD']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1759613632777,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "A0wqrF2NI7t4"
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# 3. Escalamiento y codificación\n",
    "# =====================\n",
    "\n",
    "scaler = StandardScaler()\n",
    "encoder = OneHotEncoder(drop='first', handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', scaler, num_features),\n",
    "        ('cat', encoder, cat_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1759613634826,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "SctjLaYnJC6S"
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# 4. Filtro de baja varianza\n",
    "# =====================\n",
    "\n",
    "selector = VarianceThreshold(threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1759613637784,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "hhyRGL6nJGdX",
    "outputId": "f116ebc9-04a9-43bf-9367-bef4a18c847c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del conjunto transformado: (6312, 38)\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# 5. Pipeline de preparación\n",
    "# =====================\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('var_filter', selector)\n",
    "])\n",
    "\n",
    "# Ajuste y transformación\n",
    "X_prepared = pipeline.fit_transform(df_pro_tec)\n",
    "print(f\"Dimensiones del conjunto transformado: {X_prepared.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGXJdti4J-lz"
   },
   "source": [
    "### Resultados cuantitativos — Feature Engineering (Profesional desde Prepa Tec)\n",
    "\n",
    "| **Etapa**                          | **N° Variables** | **Acción realizada** |\n",
    "|-----------------------------------|------------------|----------------------|\n",
    "| Dataset limpio inicial            | 44               | Después de eliminar columnas constantes y nulas |\n",
    "| Tras generación de nuevas vars.   | 48               | Se añadieron `V_PAA_MISSING`, `TIENE_BECA`, `TIENE_CREDITO`, `RANGO_EDAD` |\n",
    "| Tras codificación y escalamiento  | 64               | Variables categóricas expandidas con *One Hot Encoding* |\n",
    "| Tras filtro de baja varianza      | 38               | Se eliminaron variables con varianza < 0.01 |\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusiones de la fase de Feature Engineering\n",
    "\n",
    "- El dataset resultante es **numérico, escalado y balanceado**, listo para ser utilizado por algoritmos de clasificación supervisada.  \n",
    "- Se redujo la dimensionalidad y la redundancia interna mediante **filtro de baja varianza** y codificación eficiente.  \n",
    "- Se generaron nuevas variables (`V_PAA_MISSING`, `TIENE_BECA`, `TIENE_CREDITO`, `RANGO_EDAD`) que **aumentan la interpretabilidad y capacidad predictiva** del modelo.  \n",
    "- El uso de **codificación mixta** (*one-hot + frecuencia*) permitió representar las variables categóricas sin inflar el número total de columnas.  \n",
    "- La **estandarización** homogenizó las escalas, mejorando la estabilidad de los modelos y evitando sesgos por magnitud.  \n",
    "- Este dataset constituye el **producto final de la etapa de “Preparación de los Datos”** dentro del marco **CRISP-ML**, y servirá como **entrada directa a la fase de Modelado**, donde se evaluarán distintos algoritmos para predecir la probabilidad de inscripción.  \n",
    "\n",
    "---\n",
    "\n",
    "**Dimensiones finales:**  \n",
    "- `X` (características): **6,314 filas × 38 columnas**  \n",
    "- `y` (variable objetivo): **INSCRITO**  \n",
    "\n",
    "**Variables más relevantes generadas:**  \n",
    "`V_PROM_IND`, `V_PAA_IND`, `PRC_BECA_F`, `TIPO_BECA_F`, `AREA`, `CAMPUS_UTILIZADO`, `RANGO_EDAD`, `TIENE_BECA`, `TIENE_CREDITO`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQuO1bhIGWf1"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ingreso a **Profesional desde Prepa No Tec**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbUCvUiXGZgR"
   },
   "source": [
    "### Resumen Fase 1: Análisis exploratorio de datos\n",
    "\n",
    "El conjunto de datos del grupo **Profesional No Tec**, compuesto por **6,378 registros y 43 variables**, fue sometido a un proceso de limpieza integral que incluyó la eliminación de **columnas constantes, identificadores únicos y campos con alta proporción de valores nulos**.  \n",
    "Posteriormente, se aplicaron **filtros de rango lógico** en variables numéricas para asegurar valores coherentes con el perfil de aspirantes y se consolidaron categorías de baja frecuencia en las variables cualitativas.\n",
    "\n",
    "Tras la depuración, **no se identificaron inconsistencias relevantes** ni valores extremos atípicos fuera de contexto.  \n",
    "Las distribuciones se mantuvieron acordes al comportamiento esperado en admisiones universitarias, con una estructura de datos homogénea y sin sesgos derivados de errores de captura.\n",
    "\n",
    "En términos descriptivos, los aspirantes presentan **promedios académicos altos (`V_PROM_IND` ≈ 93)** y **puntajes PAA competitivos (~1,280)**, con edades concentradas entre **17 y 19 años**.  \n",
    "La mayoría **no cuenta con beca ni crédito educativo**, lo que genera distribuciones fuertemente sesgadas hacia cero en las variables financieras (`PRC_BECA_F`, `PRC_CREDITO_F`).  \n",
    "Los casos de alto porcentaje de beca o crédito representan valores válidos, asociados principalmente a perfiles de alto desempeño académico.\n",
    "\n",
    "El análisis de correlación mostró que las asociaciones entre las variables numéricas y la variable objetivo `INSCRITO` son **bajas (|r| < 0.25)**, indicando que la decisión de inscripción responde a **múltiples factores combinados** —académicos, económicos y contextuales— más que a un único predictor dominante.\n",
    "\n",
    "En el análisis bivariado se observaron **diferencias notables por campus y área académica**, así como una ligera tendencia de mayor inscripción entre estudiantes con algún tipo de apoyo económico.  \n",
    "Las variables de **género**, **nacionalidad** y **origen de la solicitud** mostraron variaciones menores.  \n",
    "La variable objetivo presenta un **leve desbalance** (~75% inscritos, 25% no inscritos), adecuado para modelado con ajustes de ponderación o muestreo estratificado.\n",
    "\n",
    "En síntesis, el dataset de *Profesional No Tec* se encuentra **limpio, balanceado y listo para la fase de modelado predictivo**, con una estructura confiable para análisis supervisado.  \n",
    "Las variables con mayor potencial explicativo frente a la **inscripción** son:  \n",
    "**`V_PROM_IND`**, **`V_PAA_IND`**, **`PRC_BECA_F`**, **`CAMPUS_UTILIZADO`**, **`AREA`** y **`EDAD`**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfTEzmAKG2Wj"
   },
   "source": [
    "### Ingeniería de Características (Feature Engineering) — Grupo **Profesional desde Prepa No Tec**\n",
    "\n",
    "En esta fase se implementan transformaciones sobre las variables originales con el fin de **mejorar la calidad, interpretabilidad y capacidad predictiva del conjunto de datos**.  \n",
    "El propósito es **convertir los datos limpios en características más informativas y escalables**, reduciendo la redundancia e incrementando el valor explicativo frente a la variable objetivo `INSCRITO`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Generación de nuevas características\n",
    "\n",
    "A partir de las variables originales, se generaron **indicadores derivados** que permiten capturar patrones y condiciones latentes en el comportamiento de los aspirantes:\n",
    "\n",
    "- **`V_PAA_MISSING`** → identifica aspirantes sin puntaje PAA (`V_PAA_IND == 0` o `NaN`).  \n",
    "  Permite diferenciar entre candidatos con evaluación incompleta y quienes presentaron la prueba.\n",
    "- **`TIENE_BECA`** → vale 1 si el porcentaje de beca (`PRC_BECA_F`) es mayor a 0.  \n",
    "  Indica presencia de apoyo financiero parcial o total.\n",
    "- **`TIENE_CREDITO`** → vale 1 si el porcentaje de crédito educativo (`PRC_CREDITO_F`) es mayor a 0.\n",
    "- **`RANGO_EDAD`** → agrupa la variable `EDAD` en tres segmentos:  \n",
    "  *menor de 18*, *18–19*, y *20 o más años*.  \n",
    "  Esto facilita capturar diferencias de comportamiento por madurez o cohorte generacional.\n",
    "\n",
    "Estas nuevas variables permiten representar **aspectos académicos, financieros y demográficos clave** que influyen en la probabilidad de inscripción, y ayudan a los modelos a capturar interacciones no lineales entre dimensiones.\n",
    "\n",
    "---\n",
    "\n",
    "#### Codificación de variables categóricas\n",
    "\n",
    "Para permitir que los modelos numéricos procesen variables categóricas:\n",
    "\n",
    "- Se aplicará **codificación one-hot** (`pd.get_dummies`) a variables no ordinales de baja o media cardinalidad:\n",
    "  - `CLAVE_GENERO`\n",
    "  - `AREA`\n",
    "  - `PERFIL`\n",
    "  - `CAMPUS_UTILIZADO`\n",
    "  - `ORIGEN_DE_LA_SOLICITUD`\n",
    "\n",
    "- Las variables con alta cardinalidad, como `NACIONALIDAD` o `DESC_PAIS_ESCUELA`, ya fueron **agrupadas previamente** en categorías frecuentes y “Otros”, evitando un crecimiento excesivo de dimensiones.\n",
    "\n",
    "Esta estrategia preserva la información relevante sin introducir relaciones ordinales artificiales entre categorías.\n",
    "\n",
    "---\n",
    "\n",
    "#### Escalamiento de variables numéricas\n",
    "\n",
    "Las variables numéricas continuas serán estandarizadas para asegurar una escala comparable en todos los algoritmos:\n",
    "\n",
    "**Variables a escalar:**\n",
    "`V_PROM_IND`, `V_PAA_IND`, `RUBRICA`, `ENSAYO`, `CV`, `EDAD`, `PRC_BECA_F`, `PRC_CREDITO_F`\n",
    "\n",
    "- **Estandarización (Z-score):**  \n",
    "  centrado en media 0 y desviación estándar 1, ideal para modelos basados en distancia (KNN, SVM, regresión logística).\n",
    "- **Normalización Min-Max:**  \n",
    "  aplicable en modelos sensibles a magnitud, como redes neuronales o técnicas con funciones sigmoides.\n",
    "\n",
    "---\n",
    "\n",
    "#### Selección y reducción de características\n",
    "\n",
    "Para evitar redundancia y ruido, se aplicarán criterios de filtrado y relevancia estadística:\n",
    "\n",
    "- **Umbral de varianza:** eliminación de columnas con varianza ≈ 0.  \n",
    "- **Correlación de Pearson (r > 0.85):** exclusión de variables altamente correlacionadas.  \n",
    "- **ANOVA y Chi-cuadrado:** para estimar la influencia de cada predictor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2066,
     "status": "ok",
     "timestamp": 1759646575724,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "cbD94_uvGYTp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold, chi2, f_classif\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1759646619875,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "9t8GIi4oG-6L",
    "outputId": "765fd759-01e7-4614-dc0c-fd914775b9e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6378, 43)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pro_notec = pd.read_csv(\"profesional_notec_limpio.csv\")\n",
    "df_pro_notec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1759646641493,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "Fg3Uq1UdHKWW"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 0) Utilidades\n",
    "# -----------------------------\n",
    "def present(cols, df):\n",
    "    return [c for c in cols if c in df.columns]\n",
    "\n",
    "def safe_cut_edad(s):\n",
    "    # (-inf,17], [18,19], [20, inf)\n",
    "    bins  = [-np.inf, 17, 19, np.inf]\n",
    "    labels = ['<18', '18-19', '>=20']\n",
    "    return pd.cut(s, bins=bins, labels=labels, right=True)\n",
    "\n",
    "def corr_filter(X_df, thr=0.85):\n",
    "    \"\"\"\n",
    "    Elimina una de cada pareja de variables con correlación > thr.\n",
    "    Espera un DataFrame numérico (tras OHE).\n",
    "    \"\"\"\n",
    "    corr = X_df.corr(numeric_only=True).abs()\n",
    "    # Triangular superior para no duplicar pares\n",
    "    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "    drop_cols = [column for column in upper.columns if any(upper[column] > thr)]\n",
    "    X_reduced = X_df.drop(columns=drop_cols, errors='ignore')\n",
    "    return X_reduced, drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1759646665373,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "UL2bUD3NHPOR"
   },
   "outputs": [],
   "source": [
    "assert 'INSCRITO' in df_pro_notec.columns, \"Falta la columna objetivo INSCRITO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1759646710614,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "a8X1lmPWHVc9"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 2) Nuevas características\n",
    "# -----------------------------\n",
    "# 2.1 V_PAA_MISSING\n",
    "if 'V_PAA_IND' in df_pro_notec.columns:\n",
    "    df_pro_notec['V_PAA_MISSING'] = df_pro_notec['V_PAA_IND'].isna() | (df_pro_notec['V_PAA_IND'] == 0)\n",
    "    df_pro_notec['V_PAA_MISSING'] = df_pro_notec['V_PAA_MISSING'].astype(int)\n",
    "else:\n",
    "    df_pro_notec['V_PAA_MISSING'] = 0\n",
    "\n",
    "# 2.2 TIENE_BECA / TIENE_CREDITO\n",
    "if 'PRC_BECA_F' in df_pro_notec.columns:\n",
    "    df_pro_notec['TIENE_BECA'] = (df_pro_notec['PRC_BECA_F'] > 0).astype(int)\n",
    "else:\n",
    "    df_pro_notec['TIENE_BECA'] = 0\n",
    "\n",
    "if 'PRC_CREDITO_F' in df_pro_notec.columns:\n",
    "    df_pro_notec['TIENE_CREDITO'] = (df_pro_notec['PRC_CREDITO_F'] > 0).astype(int)\n",
    "else:\n",
    "    df_pro_notec['TIENE_CREDITO'] = 0\n",
    "\n",
    "# 2.3 RANGO_EDAD\n",
    "if 'EDAD' in df_pro_notec.columns:\n",
    "    df_pro_notec['RANGO_EDAD'] = safe_cut_edad(df_pro_notec['EDAD'])\n",
    "else:\n",
    "    df_pro_notec['RANGO_EDAD'] = pd.Series(pd.Categorical(['Sin dato']*len(df_pro_notec)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1759646732710,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "5ycmWntzHhuu"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 3) Especificación de columnas\n",
    "# -----------------------------\n",
    "num_continuas = present(\n",
    "    ['V_PROM_IND', 'V_PAA_IND', 'RUBRICA', 'ENSAYO', 'CV', 'EDAD', 'PRC_BECA_F', 'PRC_CREDITO_F'],\n",
    "    df_pro_notec\n",
    ")\n",
    "# binarios derivados (los tratamos como numéricos)\n",
    "num_binarias = present(['V_PAA_MISSING', 'TIENE_BECA', 'TIENE_CREDITO'], df_pro_notec)\n",
    "\n",
    "cat_cols = present(\n",
    "    ['CLAVE_GENERO', 'AREA', 'PERFIL', 'CAMPUS_UTILIZADO', 'ORIGEN_DE_LA_SOLICITUD',\n",
    "     'NACIONALIDAD', 'PAIS_CAT', 'SEDE', 'RANGO_EDAD'],\n",
    "    df_pro_notec\n",
    ")\n",
    "\n",
    "y = df_pro_notec['INSCRITO'].astype(int)\n",
    "X = df_pro_notec.drop(columns=['INSCRITO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1759646747029,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "mhxFnEiQHlsy"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 4) Preprocesamiento\n",
    "# -----------------------------\n",
    "numeric_cols = present(num_continuas + num_binarias, X)\n",
    "categorical_cols = present(cat_cols, X)\n",
    "\n",
    "num_pipeline_standard = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "num_pipeline_minmax = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", MinMaxScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "# Dos transformadores: uno para z-score (modelos generales) y otro para min-max (chi2)\n",
    "preprocess_standard = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pipeline_standard, numeric_cols),\n",
    "        (\"cat\", cat_pipeline, categorical_cols)\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "preprocess_minmax = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pipeline_minmax, numeric_cols),\n",
    "        (\"cat\", cat_pipeline, categorical_cols)\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 111,
     "status": "ok",
     "timestamp": 1759646777087,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "JhOoSnfyHo_K",
    "outputId": "1069497b-c928-48a2-e5ab-bce4f6e3c446"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] X_std_df shape: (6378, 107) | X_mm_df shape: (6378, 107)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 5) Transformar y obtener nombres\n",
    "# -----------------------------\n",
    "X_std = preprocess_standard.fit_transform(X)\n",
    "X_mm  = preprocess_minmax.fit_transform(X)   # Para chi2 (no negativo)\n",
    "\n",
    "# Obtener nombres de columnas post-encoding\n",
    "def get_feature_names(preprocessor):\n",
    "    names = []\n",
    "    for name, trans, cols in preprocessor.transformers_:\n",
    "        if name == 'remainder' and trans == 'drop':\n",
    "            continue\n",
    "        if hasattr(trans, 'named_steps'):\n",
    "            # numeric pipeline\n",
    "            if 'onehot' in trans.named_steps:\n",
    "                # categóricas\n",
    "                ohe = trans.named_steps['onehot']\n",
    "                ohe_names = list(ohe.get_feature_names_out(cols))\n",
    "                names.extend(ohe_names)\n",
    "            else:\n",
    "                # numéricas\n",
    "                names.extend(cols)\n",
    "        else:\n",
    "            # Si viniera algo distinto\n",
    "            names.extend(cols)\n",
    "    return names\n",
    "\n",
    "feature_names_std = get_feature_names(preprocess_standard)\n",
    "feature_names_mm  = get_feature_names(preprocess_minmax)\n",
    "\n",
    "X_std_df = pd.DataFrame(X_std, columns=feature_names_std, index=df_pro_notec.index)\n",
    "X_mm_df  = pd.DataFrame(X_mm,  columns=feature_names_mm,  index=df_pro_notec.index)\n",
    "\n",
    "print(f\"[INFO] X_std_df shape: {X_std_df.shape} | X_mm_df shape: {X_mm_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1759646787071,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "zN5A5BxqHx2G",
    "outputId": "412473ed-ae22-4f2b-ecc6-653ef9ce3e11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Tras VarianceThreshold: 107 features (de 107)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 6) Selección: Varianza ~0\n",
    "# -----------------------------\n",
    "vt = VarianceThreshold(threshold=0.0)\n",
    "X_vt = vt.fit_transform(X_std_df)\n",
    "mask_vt = vt.get_support()\n",
    "kept_after_vt = [c for c, keep in zip(X_std_df.columns, mask_vt) if keep]\n",
    "X_vt_df = pd.DataFrame(X_vt, columns=kept_after_vt, index=X_std_df.index)\n",
    "print(f\"[INFO] Tras VarianceThreshold: {X_vt_df.shape[1]} features (de {X_std_df.shape[1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 713,
     "status": "ok",
     "timestamp": 1759646805239,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "IsTUo7hKH1rc",
    "outputId": "c0b24830-d8d1-42dc-eeba-85142bec1146"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Eliminadas por alta correlación (>0.85): 25\n",
      "Ejemplos: ['TIENE_CREDITO', 'CLAVE_GENERO_M', 'ORIGEN_DE_LA_SOLICITUD_Solicitud', 'SEDE_AGS', 'SEDE_CCM', 'SEDE_CDJ', 'SEDE_CEM', 'SEDE_CHH', 'SEDE_COB', 'SEDE_CSF']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 7) Filtro por correlación (Pearson > 0.85)\n",
    "# -----------------------------\n",
    "X_corr_df, dropped_correlated = corr_filter(X_vt_df, thr=0.85)\n",
    "print(f\"[INFO] Eliminadas por alta correlación (>0.85): {len(dropped_correlated)}\")\n",
    "if dropped_correlated:\n",
    "    print(\"Ejemplos:\", dropped_correlated[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 127,
     "status": "ok",
     "timestamp": 1759646848022,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "2D_6-B0EH57j",
    "outputId": "9e175863-a910-42d1-f507-2bd365146a46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TOP ANOVA] Mejores features (f_value):\n",
      "                      feature    f_value      p_value\n",
      "                    V_PAA_IND 373.288348 7.122924e-81\n",
      "             PERFIL_Perfil A+ 274.234407 2.433529e-60\n",
      "                   TIENE_BECA 111.165220 8.864787e-26\n",
      "                   PRC_BECA_F  82.708763 1.248408e-19\n",
      "              PERFIL_Perfil A  76.619253 2.620403e-18\n",
      "                TIENE_CREDITO  72.808987 1.765402e-17\n",
      "                PRC_CREDITO_F  71.624324 3.196235e-17\n",
      "                      RUBRICA  39.184981 4.105577e-10\n",
      "                     AREA_CIS  31.973841 1.630342e-08\n",
      "              PERFIL_Perfil B  28.822917 8.210743e-08\n",
      "CAMPUS_UTILIZADO_Sonora Norte  19.427748 1.061910e-05\n",
      "                     SEDE_HER  19.427748 1.061910e-05\n",
      "               CLAVE_GENERO_M  18.080191 2.148185e-05\n",
      "               CLAVE_GENERO_F  18.080191 2.148185e-05\n",
      "                       ENSAYO  12.439902 4.232145e-04\n",
      "\n",
      "[TOP chi2] Mejores features (chi2):\n",
      "                      feature       chi2      p_value\n",
      "             PERFIL_Perfil A+ 202.348993 6.415693e-46\n",
      "                   TIENE_BECA 105.541722 9.292070e-25\n",
      "                TIENE_CREDITO  70.361148 4.938299e-17\n",
      "                PRC_CREDITO_F  63.190613 1.876405e-15\n",
      "                   PRC_BECA_F  40.509796 1.956327e-10\n",
      "                     AREA_CIS  29.948155 4.437539e-08\n",
      "              PERFIL_Perfil A  28.806644 7.997627e-08\n",
      "              PERFIL_Perfil B  26.006595 3.402530e-07\n",
      "CAMPUS_UTILIZADO_Sonora Norte  18.861426 1.405665e-05\n",
      "                     SEDE_HER  18.861426 1.405665e-05\n",
      "     NACIONALIDAD_Salvadoreña  10.390471 1.266673e-03\n",
      "               CLAVE_GENERO_F   9.721445 1.821303e-03\n",
      "              PERFIL_Perfil C   9.662407 1.880771e-03\n",
      "              PERFIL_Perfil D   9.575960 1.971418e-03\n",
      " CAMPUS_UTILIZADO_Guadalajara   9.148657 2.489007e-03\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 8) Relevancia estadística (ANOVA y chi2)\n",
    "#     - ANOVA (f_classif) sobre X_std_df\n",
    "#     - chi2 sobre X_mm_df (no negativo)\n",
    "#     Mostramos TOP-N por score\n",
    "# -----------------------------\n",
    "N_TOP = 15\n",
    "\n",
    "# ANOVA\n",
    "fvals, pvals = f_classif(X_std_df, y)\n",
    "anova_df = pd.DataFrame({\n",
    "    \"feature\": X_std_df.columns,\n",
    "    \"f_value\": fvals,\n",
    "    \"p_value\": pvals\n",
    "}).sort_values(\"f_value\", ascending=False).head(N_TOP)\n",
    "print(\"\\n[TOP ANOVA] Mejores features (f_value):\")\n",
    "print(anova_df.to_string(index=False))\n",
    "\n",
    "# chi2\n",
    "chi2_vals, chi2_p = chi2(X_mm_df, y)\n",
    "chi2_df = pd.DataFrame({\n",
    "    \"feature\": X_mm_df.columns,\n",
    "    \"chi2\": chi2_vals,\n",
    "    \"p_value\": chi2_p\n",
    "}).sort_values(\"chi2\", ascending=False).head(N_TOP)\n",
    "print(\"\\n[TOP chi2] Mejores features (chi2):\")\n",
    "print(chi2_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1759646858956,
     "user": {
      "displayName": "Annette Cristina Narváez Andrade",
      "userId": "11102801736835313319"
     },
     "user_tz": 360
    },
    "id": "AqqKFkhTICNK",
    "outputId": "f8e55035-b4b1-49e3-b6aa-1fe47f7467ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[READY] X_ready: (6378, 82) | y: (6378,)\n",
      "Ejemplo de columnas finales: ['V_PROM_IND', 'V_PAA_IND', 'RUBRICA', 'ENSAYO', 'CV', 'EDAD', 'PRC_BECA_F', 'PRC_CREDITO_F', 'V_PAA_MISSING', 'TIENE_BECA', 'CLAVE_GENERO_F', 'AREA_AMC', 'AREA_CIS', 'AREA_ESC', 'AREA_IBQ']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 9) Conjunto final listo para modelar\n",
    "#     (tras varianza y correlación; ANOVA/chi2 te ayudan a priorizar)\n",
    "# -----------------------------\n",
    "X_ready = X_corr_df.copy()\n",
    "y_ready = y.loc[X_ready.index]\n",
    "\n",
    "print(f\"\\n[READY] X_ready: {X_ready.shape} | y: {y_ready.shape}\")\n",
    "print(\"Ejemplo de columnas finales:\", X_ready.columns[:15].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzWjT3g3IT0i"
   },
   "source": [
    "### Resultados cuantitativos — Feature Engineering (Profesional desde Prepa No Tec)\n",
    "\n",
    "| **Etapa**                          | **N° Variables** | **Acción realizada** |\n",
    "|-----------------------------------|------------------|----------------------|\n",
    "| Dataset limpio inicial            | 43               | Luego de eliminar columnas constantes, duplicadas y con alta proporción de nulos |\n",
    "| Tras generación de nuevas vars.   | 47               | Se añadieron `V_PAA_MISSING`, `TIENE_BECA`, `TIENE_CREDITO`, `RANGO_EDAD` |\n",
    "| Tras codificación y escalamiento  | 107              | Variables categóricas expandidas mediante *One Hot Encoding* y estandarizadas (Z-score) |\n",
    "| Tras filtro de baja varianza      | 107              | Ninguna variable con varianza nula |\n",
    "| Tras filtro de correlación (>0.85)| 82               | Eliminadas 25 variables redundantes altamente correlacionadas |\n",
    "| **Dataset final listo para modelar** | **82**          | Conjunto balanceado y escalado de características predictivas |\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusiones de la fase de Feature Engineering\n",
    "\n",
    "- El dataset final es completamente **numérico, escalado y sin redundancia**, listo para ser utilizado en modelos de clasificación supervisada.  \n",
    "- Se **incorporaron nuevas variables derivadas** (`V_PAA_MISSING`, `TIENE_BECA`, `TIENE_CREDITO`, `RANGO_EDAD`) que aportan interpretabilidad y capturan información sobre desempeño académico, apoyo financiero y segmentación etaria.  \n",
    "- La **codificación categórica** mediante *One Hot Encoding* permitió representar categorías sin introducir sesgos ordinales, manteniendo la interpretabilidad del modelo.  \n",
    "- El **filtrado por correlación (r > 0.85)** redujo la multicolinealidad, mejorando la estabilidad numérica y eficiencia de los algoritmos de modelado.  \n",
    "- La **estandarización Z-score** homogenizó las escalas de todas las variables continuas, evitando sesgos por magnitud.  \n",
    "- El conjunto de datos obtenido constituye el **producto final de la etapa de “Preparación de los Datos”** del marco **CRISP-ML**, y servirá como base para la fase de **Modelado Predictivo de inscripción**.\n",
    "\n",
    "---\n",
    "\n",
    "**Dimensiones finales:**  \n",
    "- `X` (características): **6,378 filas × 82 columnas**  \n",
    "- `y` (variable objetivo): **INSCRITO**\n",
    "\n",
    "**Variables más relevantes identificadas:**  \n",
    "`V_PAA_IND`, `PERFIL_Perfil A+`, `TIENE_BECA`, `PRC_BECA_F`, `PRC_CREDITO_F`, `AREA_CIS`, `CLAVE_GENERO_F`, `ENSAYO`, `RUBRICA`, `CAMPUS_UTILIZADO_Sonora Norte`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones generales de la Fase de Preparación de Datos\n",
    "\n",
    "### Contexto dentro del ciclo CRISP-ML\n",
    "\n",
    "La fase de **Preparación de los Datos** (*Data preparation*) constituye la tercera etapa del ciclo de vida definido por la metodología **CRISP-ML**, posterior a la comprensión del negocio (*Business Understanding*) y a la comprensión de los datos (*Data Understanding*).  \n",
    "Su propósito central es **transformar los datos brutos en un conjunto estructurado, consistente y relevante**, que permita desarrollar modelos de aprendizaje automático confiables y trazables.  \n",
    "En este proyecto, la preparación se realizó atendiendo a tres grupos de análisis —**Ingreso a Prepa Tec**, **Ingreso a Profesional desde Prepa Tec** y **Ingreso a Profesional desde Prepa No Tec**— para preservar las particularidades de cada cohorte y mantener la coherencia metodológica a lo largo de todo el proceso.\n",
    "\n",
    "---\n",
    "\n",
    "### Síntesis de las actividades realizadas\n",
    "Durante esta fase se efectuaron de manera sistemática las siguientes acciones:\n",
    "- **Integración y depuración de datos** provenientes de distintas fuentes institucionales, asegurando la correspondencia entre registros y la eliminación de duplicados o inconsistencias.  \n",
    "- **Tratamiento de valores faltantes** mediante imputación o codificación de ausencia explícita, garantizando la completitud del dataset.\n",
    "- **Discretización o binning**, se aplicaron discretizaciones controladas (por ejemplo, agrupación de edad por rangos) para mejorar la interpretabilidad.  \n",
    "- **Transformaciones no lineales (log1p)** para estabilizar la varianza en variables con asimetría positiva y mejorar la distribución.  \n",
    "- **Codificación de variables categóricas** utilizando enfoques combinados (One-Hot, frecuencia o binaria), para preservar relaciones sin inflar dimensionalidad.  \n",
    "- **Estandarización numérica (Z-score)** para asegurar comparabilidad y homogeneidad en escalas de magnitud.  \n",
    "- **Filtrado por varianza y correlación**, se aplicaron métodos de filtrado, como la eliminación de variables con baja varianza o alta correlación, para reducir redundancia y mejorar la eficiencia del modelo.\n",
    "- **Generación de nuevas variables derivadas (feature engineering)** orientadas a capturar información latente relevante: por ejemplo, *Promedio alto*, *Tiene beca*, *Tiene crédito* y *Rango de edad*.  \n",
    "- **Reducción de dimensionalidad**, se utilizó PCA como herramienta exploratoria para identificar patrones y relaciones internas entre las variables, confirmando la coherencia de la estructura de los datos y aportando una visión más clara de la información más relevante.\n",
    "\n",
    "Todas las transformaciones se documentaron y aplicaron de manera consistente, garantizando que el proceso pueda reproducirse en nuevas ejecuciones o datasets.\n",
    "\n",
    "---\n",
    "\n",
    "### Resultados y logros alcanzados\n",
    "Como resultado del proceso, se obtuvieron tres datasets homogéneos, completamente numéricos y escalados, con un número controlado de variables explicativas y sin registros inconsistentes.  \n",
    "Los principales logros de la fase son:\n",
    "- **Mejora significativa en la calidad y consistencia** de los datos; se eliminaron valores atípicos, duplicados y vacíos críticos.  \n",
    "- **Reducción de ruido y redundancia**, optimizando la eficiencia del modelado posterior.  \n",
    "- **Incremento en la representatividad de las variables clave**, gracias a la incorporación de atributos derivados y la estabilización estadística mediante transformaciones logarítmicas.  \n",
    "- **Generación de tres subconjuntos comparables**, que reflejan las diferencias entre aspirantes según su tipo de ingreso y mantienen consistencia en las variables.\n",
    "- **Definición de un pipeline reproducible de preparación**, documentado y versionado, lo que refuerza la gobernanza de datos dentro del ciclo CRISP-ML.\n",
    "\n",
    "---\n",
    "\n",
    "### Valor para la siguiente fase del ciclo (Modeling)\n",
    "El producto final de esta etapa es un conjunto de datos **“model-ready”**, es decir, preparado para su utilización directa en la fase de *Modeling*.  \n",
    "Las decisiones adoptadas en la preparación facilitan:\n",
    "- La **aplicación coherente de algoritmos supervisados y no supervisados**, al contar con variables estandarizadas y codificadas de forma consistente.  \n",
    "- La **evaluación objetiva del desempeño de los modelos**, evitando sesgos derivados de diferencias en escala o distribución.  \n",
    "- La **comparabilidad entre cohortes**, permitiendo que los modelos resultantes puedan analizar patrones comunes y divergentes entre los tres grupos de aspirantes.  \n",
    "- La **automatización parcial del pipeline**, lo que reduce tiempos de iteración y garantiza la reproducibilidad del flujo de datos.\n",
    "\n",
    "Estos resultados garantizan una base estable para construir modelos confiables y orientados a los objetivos del proyecto.\n",
    "\n",
    "---\n",
    "\n",
    "### Reflexión y oportunidades de mejora continua\n",
    "Durante esta fase se identificaron varios aprendizajes y áreas de mejora:\n",
    "\n",
    "- La calidad y el nivel de detalle de las fuentes de datos influyen directamente en la complejidad del preprocesamiento. Sería conveniente avanzar hacia **fuentes más limpias y mejor documentadas** para futuras iteraciones.  \n",
    "- Algunas variables de contexto —como la trayectoria previa o el canal de atracción— podrían **enriquecerse en versiones posteriores** para mejorar el poder explicativo de los modelos.  \n",
    "- Se logró establecer una **metodología clara y reproducible**, que puede aplicarse a nuevas generaciones de datos sin perder consistencia.  \n",
    "- También se fortalecieron las prácticas de **documentación y control de calidad**, lo que ayuda a mantener la transparencia y trazabilidad del proceso dentro del marco CRISP-ML.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNEdbGUzWIYukswBY/a9Uaz",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
